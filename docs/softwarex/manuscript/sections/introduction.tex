% Section 1: Motivation and significance
\section{Motivation and significance}

Modern forest harvesting optimisation problems mirror the increasing complexity highlighted in recent SoftwareX exemplars: planners need transparent tooling that spans planning horizons, integrates heterogeneous data sources, and supports reproducible experimentation \cite{Lyden2021PyLESA,Schwarz2021pycity}. Today, most harvesting groups still rely on spreadsheet point solutions or proprietary solvers that are difficult to audit; every new scenario (e.g., introducing skyline systems, injecting salvage corridors, calibrating productivity models) triggers a bespoke analysis loop. FHOPS targets this gap by packaging the optimisation heuristics, MIP constructs, scenario contract, and evaluation telemetry we already operate in production into a single, research-friendly stack. Like PyLESA, we state explicit gaps up front—multi-problem workflows, telemetry-backed reproducibility, solver governance, shared datasets—and show how FHOPS compresses the “scoping → benchmarking → deployment” loop for harvesting teams.

The manuscript therefore makes three contributions:
1. **Architecture + data contract** – We formalise the FHOPS architecture (scenario ingestion, optimisation services, telemetry) so planners can reason about model scope and reproduce results outside our internal environment. This mirrors the clarity PyLESA and pycity\_scheduling offer for energy-system modelling.
2. **Benchmark + reproducibility tooling** – We publish a benchmark matrix (scheduling, routing, resource allocation) with scripts that regenerate KPI tables/plots via one command, following the best practices PyDDRBG and cashocs established.
3. **Governance + adoption evidence** – We document the governance model (release cadence, contributor process, validation suite) and provide adoption metrics akin to libxc/MOOSE/GROMACS so reviewers can see FHOPS’ community impact.

Section~\ref{sec:software-description} decomposes the software into ingest, optimisation, and evaluation layers and shows how they interact with the open data catalogue. Section~\ref{sec:illustrative-example} walks through a benchmark suite spanning three optimisation classes and the telemetry/CI hooks that keep it reproducible. Section~\ref{sec:impact} quantifies adoption plus governance processes inspired by libxc/MOOSE, and we close with the roadmap and submission logistics to keep FHOPS aligned with the reproducibility signals SoftwareX emphasises \cite{Blauth2023cashocs}.
